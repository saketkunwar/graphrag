{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<span style=\"color:darkolivegreen;font-weight:800;font-size:32px\">\n    Building Agentic Apps: ArangoDB, NVIDIA cuGraph, and NetworkX Hackathon\n</span>\n\n<br>\n\n<p align=\"center\">\n    <img src=\"https://arangodb.com/wp-content/uploads/2016/05/ArangoDB_logo_avocado_@1.png\" style=\"height: 50px;\">\n    <img src=\"https://www.nvidia.com/content/dam/en-zz/Solutions/about-nvidia/logo-and-brand/02-nvidia-logo-color-grn-500x200-4c25-p@2x.png\" style=\"height: 50px;\">\n    <img src=\"https://rapids.ai/images/RAPIDS-logo.png\" style=\"height: 50px;\">\n    <img src=\"https://avatars.githubusercontent.com/u/388785?s=200&v=4\" style=\"height: 50px;\">\n</p>","metadata":{"execution":{"iopub.status.busy":"2025-03-04T08:33:32.600215Z","iopub.execute_input":"2025-03-04T08:33:32.60051Z","iopub.status.idle":"2025-03-04T08:33:32.607055Z","shell.execute_reply.started":"2025-03-04T08:33:32.60048Z","shell.execute_reply":"2025-03-04T08:33:32.605646Z"}}},{"cell_type":"markdown","source":"Imagine competing in a high-stakes hackathon where the cutting edge of AI - Agentic Applications, GraphRAG, and NVIDIA cuGraph GPU-accelerated graph analytics - converge to redefine the future of GenAI-powered business solutions. With GraphRAG emerging as the most advanced Retrieval-Augmented Generation (RAG) approach, this competition challenges you to develop an intelligent agent that can query and reason over graph data with precision and efficiency.\n\n### **Why GraphRAG**?\nTraditional RAG systems rely solely on vector-based retrieval, which can lead to hallucinations, context fragmentation, and a lack of structured reasoning. GraphRAG addresses these shortcomings by integrating graph-based retrieval, preserving contextual relationships between entities and enabling more accurate, structured, and interpretable AI-generated responses.  \nBy leveraging GraphRAG, participants can minimize hallucinations, improve knowledge retrieval, and enhance AI-generated insights—a fundamental breakthrough for enterprises using generative AI in business-critical applications.\n\n### **Your Mission**\nBuild an Agentic Application that integrates GraphRAG and GPU-accelerated graph analytics to solve a real-world problem.  \nParticipants have two dataset options:\n- **Bring Your Own Data (BYOD)** – Select an open dataset relevant to your use case.\n- **Use ArangoDB’s Provided Dataset** – A pre-configured dataset optimized for graph analytics and GraphRAG tasks.\n\nTo streamline development, ArangoDB will provide a sample Jupyter Notebook with pre-built placeholders to help structure each step of the process.\n","metadata":{}},{"cell_type":"markdown","source":"[**ArangoDB**](https://arangodb.com/) is a multi-model, open-source NoSQL database that supports graph, document, and key-value data models within a single database engine. This flexibility enables developers to handle complex, interconnected data with ease, as opposed to traditional databases that might require multiple systems for different data types. ArangoDB is designed to provide scalability, reliability, and speed, and is commonly used for applications requiring real-time analytics, social networks, recommendation engines, and other data-intensive workloads.\n\n**Key Features of ArangoDB**\n\n1. **Multi-Model Approach**: \n   - ArangoDB supports different data models: Document (similar to MongoDB), Graph (similar to Neo4j), Search (similar to ElasticSearch), and (most recently) Vector (similar to FAISS). This multi-model approach allows developers to choose the best model for different parts of their application without needing to integrate multiple databases.\n\n2. **AQL (Arango Query Language)**: \n   - ArangoDB uses its own query language, AQL, which is similar to SQL but tailored for its multi-model structure. It supports complex queries across graphs, documents, and key-value stores, simplifying development and reducing the need for complex joins between different data stores.\n\n3. **Horizontal Scaling**: \n   - ArangoDB supports sharding, replication, and distributed deployments, ensuring that applications can scale horizontally, distributing data across multiple servers while maintaining high availability.\n\n4. **ACID Transactions**: \n   - Unlike some NoSQL databases, ArangoDB offers ACID-compliant transactions, making it suitable for applications requiring strong consistency and reliability.\n\n5. **Graph Processing**: \n   - The graph database model is particularly useful for applications that need to process relationships between entities, such as social media platforms, fraud detection systems, or knowledge graphs.\n\n**Relationship with NVIDIA**\n\nThe close relationship between **ArangoDB** and **NVIDIA** stems from the increasing need for high-performance data processing, particularly in graph analytics and AI-related workloads. NVIDIA, known for its leadership in GPU technologies, provides the computational power necessary to accelerate certain database operations, especially those related to complex analytics.\n\nKey Points in the relationship:\n\n1. **GPU Acceleration for Graph Processing**:\n   - Graph analytics is a computationally intensive task, and the parallel processing power of NVIDIA GPUs can significantly speed up graph-related queries. ArangoDB has explored integrating GPU acceleration for graph queries and other high-performance data processing tasks, which helps in reducing the time required to analyze complex networks of data.\n\n2. **AI/ML Integration**:\n   - With the rise of AI and machine learning, ArangoDB’s ability to handle multi-model data is crucial. NVIDIA’s technologies, such as GPUs and CUDA (Compute Unified Device Architecture), can accelerate machine learning models and data pipelines that interact with ArangoDB, improving overall performance and enabling real-time analytics for AI-based applications.\n\n3. **Collaborative Projects**:\n   - NVIDIA and ArangoDB have explored joint initiatives to enhance the database’s performance, particularly in the context of graph-based machine learning and AI research. This includes optimizing database queries and enabling more efficient data processing workflows, which can be crucial for industries like finance, healthcare, and autonomous driving.","metadata":{"execution":{"iopub.status.busy":"2025-03-04T08:34:28.169556Z","iopub.execute_input":"2025-03-04T08:34:28.169859Z","iopub.status.idle":"2025-03-04T08:34:28.179912Z","shell.execute_reply.started":"2025-03-04T08:34:28.169836Z","shell.execute_reply":"2025-03-04T08:34:28.178787Z"}}},{"cell_type":"markdown","source":"NetworkX is a Python package for the creation, manipulation, and study of the structure, dynamics, and functions of complex networks. It provides:\n* tools for the study of the structure and dynamics of social, biological, and infrastructure networks;\n* a standard programming interface and graph implementation that is suitable for many applications;\n* a rapid development environment for collaborative, multidisciplinary projects;\n* an interface to existing numerical algorithms and code written in C, C++, and FORTRAN; and\n* the ability to painlessly work with large nonstandard data sets.\n\nWith NetworkX you can load and store networks in standard and nonstandard data formats, generate many types of random and classic networks, analyze network structure, build network models, design new network algorithms, draw networks, and much more.","metadata":{}},{"cell_type":"markdown","source":"While NetworkX provides a tremendous amount of usability right out of the box, **performance and scalability for medium-to-large-sized networks are far from best-in-class and can significantly limit a data scientist’s productivity**.\n\nThe **RAPIDS cuGraph** project was created to bridge the gap between fast, scalable, **GPU-based graph analytics** and NetworkX ease-of-use. \n\ncuGraph was designed with NetworkX interoperability in mind, which can be seen when you replace only the `betweenness_centrality` call from the prior example with cuGraph’s `betweenness_centrality` and leave the rest of the code as-is.","metadata":{}},{"cell_type":"markdown","source":"**Meanwhile, NetworkX adds dispatching to [backends](https://networkx.org/documentation/stable/backends.html)…**\n\nNetworkX has recently added the ability to dispatch API calls to different analytic backends provided by third parties. These backends can provide alternate implementations for various NetworkX APIs that can greatly improve performance.\n\nBy enabling other graph libraries to easily extend NetworkX through backends, NetworkX becomes a standard graph analytics frontend.  This means more users can use the capabilities of other graph libraries without the learning curve and integration time associated with a new library.\n\nLibrary maintainers also benefit from NetworkX dispatching because they can reach more users without the overhead of maintaining a user-facing API. Instead, they can just focus on delivering a backend.\n\nAnd thus the first NetworkX GPU Backend was released: [nx-cugraph](https://docs.rapids.ai/api/cugraph/nightly/nx_cugraph/nx_cugraph/)","metadata":{}},{"cell_type":"markdown","source":"**However, NetworKX remains in-memory only...**\n\nThe opportunity to introduce a **Persistence Backend** was presented to ArangoDB via our parternship with NVIDIA, resulting in the release of `nx-arangodb`, and a Developer Blog Post published by NVIDIA: https://developer.nvidia.com/blog/accelerated-production-ready-graph-analytics-for-networkx-users/","metadata":{}},{"cell_type":"markdown","source":"#### **NetworkX-ArangoDB**","metadata":{"execution":{"iopub.status.busy":"2025-03-04T08:38:24.199591Z","iopub.execute_input":"2025-03-04T08:38:24.199894Z","iopub.status.idle":"2025-03-04T08:38:24.204958Z","shell.execute_reply.started":"2025-03-04T08:38:24.199871Z","shell.execute_reply":"2025-03-04T08:38:24.204124Z"}}},{"cell_type":"markdown","source":"\n`nx-arangodb` is a [backend to NetworkX](https://networkx.org/documentation/stable/reference/backends.html) that offers [ArangoDB](https://github.com/arangodb/arangodb) as a [Persistence Layer to NetworkX Graphs](https://arangodb.com/introducing-the-arangodb-networkx-persistence-layer/):\n1. Persist NetworkX Graphs to ArangoDB.\n2. Reload NetworkX Graphs from ArangoDB.\n2. Perform CRUD on ArangoDB Graphs via NetworkX.\n3. Run algorithms (CPU & GPU) on ArangoDB Graphs via NetworkX.\n\nBenefits of having ArangoDB as a backend to NetworkX include:\n1. No need to re-create the graph every time you start a new session.\n2. Access to GPU-accelerated graph analytics ([nx-cugraph](https://rapids.ai/nx-cugraph/)).\n3. Access to a database query language ([Arango Query Language](https://arangodb.com/sql-aql-comparison/)).\n4. Access to a visual interface for graph exploration ([ArangoDB Web UI](https://docs.arangodb.com/stable/components/web-interface/graphs/)).\n5. Access to cross-collaboration on the same graph ([ArangoDB Cloud](https://docs.arangodb.com/stable/get-started/set-up-a-cloud-instance/)).\n6. Access to efficient distribution of graph data ([ArangoDB SmartGraphs](https://docs.arangodb.com/stable/graphs/smartgraphs/)).\n\nAdditional Documentation:\n- [NetworkX Hello World](https://networkx.org/documentation/stable/tutorial.html)\n- [nx-cugraph](https://docs.rapids.ai/api/cugraph/nightly/nx_cugraph/nx_cugraph/)\n\n\n<p align=\"center\">\n    <img src=\"https://raw.githubusercontent.com/arangodb/nx-arangodb/main/doc/_static/nxadb.png\" style=\"height: 200px;\">\n    <img src=\"https://raw.githubusercontent.com/arangodb/nx-arangodb/main/doc/_static/dispatch.png\" style=\"height: 200px;\">\n</p>","metadata":{}},{"cell_type":"code","source":"%%capture --no-stderr\n%pip install -U langgraph langchain_community langchain_openai tavily-python langchain_huggingface langchain-google-genai","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-08T13:14:27.621631Z","iopub.execute_input":"2025-03-08T13:14:27.621930Z","iopub.status.idle":"2025-03-08T13:14:41.336953Z","shell.execute_reply.started":"2025-03-08T13:14:27.621905Z","shell.execute_reply":"2025-03-08T13:14:41.335730Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"# 1. Install nx-arangodb via pip\n# Github: https://github.com/arangodb/nx-arangodb\n\n!pip  install --quiet nx-arangodb arango-datasets","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-08T13:14:41.338301Z","iopub.execute_input":"2025-03-08T13:14:41.338645Z","iopub.status.idle":"2025-03-08T13:14:47.560152Z","shell.execute_reply.started":"2025-03-08T13:14:41.338609Z","shell.execute_reply":"2025-03-08T13:14:47.559344Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.8/67.8 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m30.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m88.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.6/114.6 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# 2. Check if you have an NVIDIA GPU\n# Note: If this returns \"command not found\", then GPU-based algorithms via cuGraph are unavailable\n\n!nvidia-smi\n!nvcc --version","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-08T13:14:47.562008Z","iopub.execute_input":"2025-03-08T13:14:47.562311Z","iopub.status.idle":"2025-03-08T13:14:47.910464Z","shell.execute_reply.started":"2025-03-08T13:14:47.562288Z","shell.execute_reply":"2025-03-08T13:14:47.909669Z"}},"outputs":[{"name":"stdout","text":"Sat Mar  8 13:14:47 2025       \n+-----------------------------------------------------------------------------------------+\n| NVIDIA-SMI 560.35.03              Driver Version: 560.35.03      CUDA Version: 12.6     |\n|-----------------------------------------+------------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n|                                         |                        |               MIG M. |\n|=========================================+========================+======================|\n|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n| N/A   33C    P8              9W /   70W |       1MiB /  15360MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n|   1  Tesla T4                       Off |   00000000:00:05.0 Off |                    0 |\n| N/A   35C    P8              9W /   70W |       1MiB /  15360MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n                                                                                         \n+-----------------------------------------------------------------------------------------+\n| Processes:                                                                              |\n|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n|        ID   ID                                                               Usage      |\n|=========================================================================================|\n|  No running processes found                                                             |\n+-----------------------------------------------------------------------------------------+\nnvcc: NVIDIA (R) Cuda compiler driver\nCopyright (c) 2005-2023 NVIDIA Corporation\nBuilt on Tue_Aug_15_22:02:13_PDT_2023\nCuda compilation tools, release 12.2, V12.2.140\nBuild cuda_12.2.r12.2/compiler.33191640_0\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# 3. Install nx-cugraph via pip\n# Note: Only enable this installation if the step above is working!\n\n!pip install --quiet nx-cugraph-cu12 --extra-index-url https://pypi.nvidia.com","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-08T13:14:47.911398Z","iopub.execute_input":"2025-03-08T13:14:47.911622Z","iopub.status.idle":"2025-03-08T13:15:03.032622Z","shell.execute_reply.started":"2025-03-08T13:14:47.911602Z","shell.execute_reply":"2025-03-08T13:15:03.031500Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m453.1/453.1 MB\u001b[0m \u001b[31m66.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m151.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncudf-cu12 25.2.0 requires rmm-cu12==25.2.*, but you have rmm-cu12 24.10.0 which is incompatible.\ncuml-cu12 25.2.0 requires pylibraft-cu12==25.2.*, but you have pylibraft-cu12 24.10.0 which is incompatible.\ncuml-cu12 25.2.0 requires rmm-cu12==25.2.*, but you have rmm-cu12 24.10.0 which is incompatible.\ncuvs-cu12 25.2.0 requires pylibraft-cu12==25.2.*, but you have pylibraft-cu12 24.10.0 which is incompatible.\npylibcudf-cu12 25.2.0 requires rmm-cu12==25.2.*, but you have rmm-cu12 24.10.0 which is incompatible.\nraft-dask-cu12 25.2.0 requires pylibraft-cu12==25.2.*, but you have pylibraft-cu12 24.10.0 which is incompatible.\nucxx-cu12 0.42.0 requires rmm-cu12==25.2.*, but you have rmm-cu12 24.10.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"from langchain_community.graphs import ArangoGraph\nfrom arango import ArangoClient\nfrom langchain_community.chains.graph_qa.arangodb import ArangoGraphQAChain\nfrom langchain_core.tools import tool\nimport huggingface_hub\nfrom langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder, PromptTemplate\nfrom langchain_huggingface import ChatHuggingFace, HuggingFaceEndpoint\nimport plotly\nimport nx_cugraph","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-08T13:15:03.033748Z","iopub.execute_input":"2025-03-08T13:15:03.034104Z","iopub.status.idle":"2025-03-08T13:15:08.147576Z","shell.execute_reply.started":"2025-03-08T13:15:03.034075Z","shell.execute_reply":"2025-03-08T13:15:08.146644Z"}},"outputs":[],"execution_count":5},{"cell_type":"raw","source":"We will be using the 'flights' graph provided by arango_db.\nLoad it into our deployment and instantiate our database and graphs from there.","metadata":{}},{"cell_type":"code","source":"import getpass\nimport os\nimport networkx as nx\nimport nx_arangodb as nxadb\ndef _set_env(var: str):\n    if not os.environ.get(var):\n        os.environ[var] = getpass.getpass(f\"{var}: \")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-08T13:15:14.608248Z","iopub.execute_input":"2025-03-08T13:15:14.608759Z","iopub.status.idle":"2025-03-08T13:15:15.146836Z","shell.execute_reply.started":"2025-03-08T13:15:14.608733Z","shell.execute_reply":"2025-03-08T13:15:15.146173Z"}},"outputs":[{"name":"stderr","text":"[13:15:15 +0000] [INFO]: NetworkX-cuGraph is available.\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"#Use your personal deployment from http:/arangodb.com\n_set_env(\"DATABASE_HOST\")\n_set_env(\"DATABASE_USERNAME\")\n_set_env(\"DATABASE_PASSWORD\")\n_set_env(\"DATABASE_NAME\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-08T13:15:38.367846Z","iopub.execute_input":"2025-03-08T13:15:38.368181Z","iopub.status.idle":"2025-03-08T13:16:04.657697Z","shell.execute_reply.started":"2025-03-08T13:15:38.368157Z","shell.execute_reply":"2025-03-08T13:16:04.657013Z"}},"outputs":[{"output_type":"stream","name":"stdin","text":"DATABASE_HOST:  ········\nDATABASE_USERNAME:  ········\nDATABASE_PASSWORD:  ········\nDATABASE_NAME:  ········\n"}],"execution_count":7},{"cell_type":"code","source":"import arango\nfrom arango import ArangoClient\nfrom langchain_community.graphs import ArangoGraph\nfrom arango import ArangoClient\nfrom langchain_community.chains.graph_qa.arangodb import ArangoGraphQAChain\nfrom arango_datasets import Datasets\n\ndb = ArangoClient(hosts=os.getenv('DATABASE_HOST')).db( \n                username=os.getenv('DATABASE_USERNAME'), \n                password=os.getenv('DATABASE_PASSWORD'), verify=True)\nprint(db)\n# Connect to datasets\ndatasets = Datasets(db)\n# List datasets\nprint(datasets.list_datasets())\n# List more information about a particular dataset\n#print(datasets.dataset_info(\"OPEN_INTELLIGENCE\"))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-08T13:16:08.164872Z","iopub.execute_input":"2025-03-08T13:16:08.165161Z","iopub.status.idle":"2025-03-08T13:16:08.629712Z","shell.execute_reply.started":"2025-03-08T13:16:08.165140Z","shell.execute_reply":"2025-03-08T13:16:08.629034Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output()","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"<StandardDatabase _system>\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"},"metadata":{}},{"name":"stdout","text":"['IMDB_X', 'IMDB_PLATFORM', 'AMAZON_COMPUTER_PRODUCTS', 'AMAZON_PRODUCT_WITH_EMBEDDINGS', 'FAKE_HOMO_MULTICLASS', 'FAKE_HOMO_BINARY', 'FAKE_HETRO_LARGE_MULTICLASS', 'MAG', 'OPEN_INTELLIGENCE', 'OPEN_INTELLIGENCE_ANGOLA', 'FLIGHTS', 'CORA', 'DBLP', 'CVE', 'MTCARS', 'P2PSB', 'SCHAIN', 'ITSM_SAGE', 'ABIDE', 'CYBER', 'GAME_OF_THRONES', 'MARKET', 'SYNTHEA_P1000', 'SYNTHEA_P100']\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"'''\nOnly if executing the first time to load dataset into personal deployment\n'''\n#Load the graph in your deployment\n#print(datasets.dataset_info(\"FLIGHTS\"))\n#datasets.load(\"Flights\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-08T13:16:16.812392Z","iopub.execute_input":"2025-03-08T13:16:16.812692Z","iopub.status.idle":"2025-03-08T13:16:16.818491Z","shell.execute_reply.started":"2025-03-08T13:16:16.812670Z","shell.execute_reply":"2025-03-08T13:16:16.817587Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"'\\nOnly if executing the first time to load dataset into personal deployment\\n'"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"#the arangodb graph persistent in personal deployment at http://aragodb.com\narango_graph = ArangoGraph(db=db)\narango_graph.schema","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-08T13:16:17.732760Z","iopub.execute_input":"2025-03-08T13:16:17.733091Z","iopub.status.idle":"2025-03-08T13:16:18.336702Z","shell.execute_reply.started":"2025-03-08T13:16:17.733064Z","shell.execute_reply":"2025-03-08T13:16:18.335830Z"}},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"{'Graph Schema': [{'graph_name': 'Flights',\n   'edge_definitions': [{'edge_collection': 'flights',\n     'from_vertex_collections': ['airports'],\n     'to_vertex_collections': ['airports']}]}],\n 'Collection Schema': [{'collection_name': 'airports',\n   'collection_type': 'document',\n   'document_properties': [{'name': '_key', 'type': 'str'},\n    {'name': '_id', 'type': 'str'},\n    {'name': '_rev', 'type': 'str'},\n    {'name': 'name', 'type': 'str'},\n    {'name': 'city', 'type': 'str'},\n    {'name': 'state', 'type': 'str'},\n    {'name': 'country', 'type': 'str'},\n    {'name': 'lat', 'type': 'float'},\n    {'name': 'long', 'type': 'float'},\n    {'name': 'vip', 'type': 'bool'}],\n   'example_document': {'_key': '00M',\n    '_id': 'airports/00M',\n    '_rev': '_jSZnJvq---',\n    'name': 'Thigpen ',\n    'city': 'Bay Springs',\n    'state': 'MS',\n    'country': 'USA',\n    'lat': 31.95376472,\n    'long': -89.23450472,\n    'vip': False}},\n  {'collection_name': 'flights',\n   'collection_type': 'edge',\n   'edge_properties': [{'name': '_key', 'type': 'str'},\n    {'name': '_id', 'type': 'str'},\n    {'name': '_from', 'type': 'str'},\n    {'name': '_to', 'type': 'str'},\n    {'name': '_rev', 'type': 'str'},\n    {'name': 'Year', 'type': 'int'},\n    {'name': 'Month', 'type': 'int'},\n    {'name': 'Day', 'type': 'int'},\n    {'name': 'DayOfWeek', 'type': 'int'},\n    {'name': 'DepTime', 'type': 'int'},\n    {'name': 'ArrTime', 'type': 'int'},\n    {'name': 'DepTimeUTC', 'type': 'str'},\n    {'name': 'ArrTimeUTC', 'type': 'str'},\n    {'name': 'UniqueCarrier', 'type': 'str'},\n    {'name': 'FlightNum', 'type': 'int'},\n    {'name': 'TailNum', 'type': 'str'},\n    {'name': 'Distance', 'type': 'int'}],\n   'example_edge': {'_key': '306520629',\n    '_id': 'flights/306520629',\n    '_from': 'airports/ATL',\n    '_to': 'airports/CHS',\n    '_rev': '_jSZnNM2---',\n    'Year': 2008,\n    'Month': 1,\n    'Day': 1,\n    'DayOfWeek': 2,\n    'DepTime': 2,\n    'ArrTime': 57,\n    'DepTimeUTC': '2008-01-01T05:02:00.000Z',\n    'ArrTimeUTC': '2008-01-01T05:57:00.000Z',\n    'UniqueCarrier': 'FL',\n    'FlightNum': 579,\n    'TailNum': 'N937AT',\n    'Distance': 259}}]}"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"#Our Flight graph is a MultiGraph(many edges(flight) between same nodes(airport))\n#And is also directional\n#We ask the prompt to convert to undirectional when required\nG_adb = nxadb.MultiDiGraph(name='Flights')\nprint(G_adb.number_of_nodes(), G_adb.number_of_edges())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-08T13:16:22.056887Z","iopub.execute_input":"2025-03-08T13:16:22.057169Z","iopub.status.idle":"2025-03-08T13:16:22.804031Z","shell.execute_reply.started":"2025-03-08T13:16:22.057148Z","shell.execute_reply":"2025-03-08T13:16:22.803343Z"}},"outputs":[{"name":"stderr","text":"[13:16:22 +0000] [INFO]: Graph 'Flights' exists.\n[13:16:22 +0000] [INFO]: Default node type set to 'airports'\n","output_type":"stream"},{"name":"stdout","text":"3375 275167\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"# gemini 2.0 falsh works well too and has higher free rate limits\n# gemini 2.0 flash-lite also was found to be suitable for PLotly and Folium vizualisation tool\nuse_model='openai' #one of ['gemini', 'openai']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-08T13:16:24.723134Z","iopub.execute_input":"2025-03-08T13:16:24.723474Z","iopub.status.idle":"2025-03-08T13:16:24.727257Z","shell.execute_reply.started":"2025-03-08T13:16:24.723448Z","shell.execute_reply":"2025-03-08T13:16:24.726310Z"}},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":"Set the **Main reasoning and planning model **for planning, re-planning, solving ","metadata":{}},{"cell_type":"code","source":"import os\nif use_model=='gemini':\n    _set_env(\"GOOGLE_API_KEY\")\n    from langchain_google_genai import ChatGoogleGenerativeAI\n    model_name = \"gemini-2.0-flash\"\n    model = ChatGoogleGenerativeAI(\n        model=model_name,\n        temperature=0,\n        max_tokens=None,\n        timeout=None,\n        max_retries=2,\n        # other params...\n    )\nif use_model=='openai':\n    _set_env(\"OPENAI_API_KEY\")\n    from langchain_openai import ChatOpenAI\n    model_name = 'gpt-4o'\n    model = ChatOpenAI(temperature=0, model_name=model_name)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-08T13:16:27.422113Z","iopub.execute_input":"2025-03-08T13:16:27.422542Z","iopub.status.idle":"2025-03-08T13:16:50.164605Z","shell.execute_reply.started":"2025-03-08T13:16:27.422506Z","shell.execute_reply":"2025-03-08T13:16:50.163901Z"}},"outputs":[{"output_type":"stream","name":"stdin","text":"OPENAI_API_KEY:  ········\n"}],"execution_count":13},{"cell_type":"markdown","source":"**TOOLS and Examples**","metadata":{}},{"cell_type":"code","source":"# 4. Define the Text to AQL Tool\n# Reference: https://python.langchain.com/docs/integrations/graphs/arangodb/\n# Reference: https://python.langchain.com/api_reference/community/chains/langchain_community.chains.graph_qa.arangodb.ArangoGraphQAChain.html\n# Note: It is encouraged to experiment and improve this section! This is just a placeholder:\nfrom langchain_core.tools import tool\nexamples='''\nExamples:\nexample 1:\nquestion: Which airline has the most flights originating from airports located in the city of 'Los Angeles'?\"\naql: \nLET la_airports = (\n    FOR a IN airports\n        FILTER a.city == \"Los Angeles\"\n        RETURN a._id\n)\n\nFOR f IN flights\n    FILTER f._from IN la_airports\n    COLLECT carrier = f.UniqueCarrier WITH COUNT INTO num_flights\n    SORT num_flights DESC\n    LIMIT 1\n    RETURN {\n        airline: carrier,\n        num_flights\n    }\n\nexample 2:\nquestion: List all the distinct destination cities that are directly reachable from airports in 'Chicago', along with the IATA codes of the Chicago airports from which those flights depart.\naql: \nLET chicago_airports = (\n    FOR a IN airports\n        FILTER a.city == \"Chicago\"\n        RETURN a._id\n)\n\nFOR f IN flights\n    FILTER f._from IN chicago_airports\n    FOR dest_airport IN airports\n        FILTER f._to == dest_airport._id\n        COLLECT destination_city = dest_airport.city, origin_airport_key = f._from\n        RETURN {\n            destination_city,\n            origin_airport_key\n        }\n        \nexample 3:\nquestion: Starting from the airport with IATA code 'JFK', what are the names and IATA codes of all airports that I can reach with no or at max single connecting flight (i.e., two flights total max)?\naql:\nLET jfk_airport = (\n    FOR a IN airports\n        FILTER a._key == \"JFK\"\n        RETURN a._id\n)\n\nFOR v, e, p IN 1..2 OUTBOUND jfk_airport[0] flights\n    RETURN DISTINCT {\n        airport_name: v.name,\n        airport_key: v._key\n    }\n    \nexample 4:\nquestion: How far do I have to travel from longitude=3.05 and latitude 36.7\nto the nearest airport?\naql:\nLET user_location = GEO_POINT(-117.9189, 33.8117)  // Use the longitude and latitude\n\nFOR airport IN airports\n    LET distance = GEO_DISTANCE(user_location, GEO_POINT(airport.long, airport.lat))\n    SORT distance ASC\n    LIMIT 1\n    RETURN {\n        airport_key: airport._key,\n        airport_name: airport.name,\n        distance_meters: distance,\n        distance_miles: distance / 1609.34 // Convert meters to miles\n    }\n    \nexample 5:\nquestion: for the airport in [\"FUL\", \"SNA\", \"LGB\", \"CPM\", \"AJO\"], get the airline and flight count\naql:\nWITH airports, flights\nLET airport_keys = [\"FUL\", \"SNA\", \"LGB\", \"CPM\", \"AJO\"]\n\nFOR airport_key IN airport_keys\n    LET airport = FIRST(FOR a IN airports FILTER a._key == airport_key RETURN a)\n\n    LET results = (\n        FOR f IN flights\n            FILTER f._from == (airport != null ? CONCAT(\"airports/\", airport_key) : null)\n            COLLECT airline = f.UniqueCarrier WITH COUNT INTO num_flights\n            RETURN {\n                airline: airline,\n                num_flights: num_flights\n            }\n    )\n    RETURN {\n      airport_name: airport != null ? airport.name : null,\n      airlines: airport != null ? results : []\n    }\n'''\n@tool\ndef text_to_aql_to_text(query: str):\n    \"\"\"This tool is available to invoke the\n    ArangoGraphQAChain object, which enables you to\n    translate a Natural Language Query into AQL, execute\n    the query and translate the result back into Natural Language.\n    If the query to AQL requires sub queries then combine at the end.\n    When working with geographic information use the built-in GEO functions\n    such as GEO_DISTANCE instead of DISTANCE to calculate distances between geo points.\n    \"\"\"\n    #llm = ChatHuggingFace(llm=hf_coder)\n    if use_model=='gemini':\n        llm  =  ChatGoogleGenerativeAI(\n        model=model_name,\n        temperature=0,\n        max_tokens=None,\n        timeout=None,\n        max_retries=2,\n        # other params...\n        )\n    if use_model=='openai':\n        llm = ChatOpenAI(temperature=0, model_name=model_name)\n    # --- Chain Setup ---\n    \n    qa_chain = ArangoGraphQAChain.from_llm(\n        llm,\n        graph=arango_graph,\n        aql_examples=examples,\n        allow_dangerous_requests=True,\n        verbose=True,  # See the generated queries and errors\n        max_aql_generation_attempts = 5\n    )\n    result = qa_chain.invoke(query)\n    return str(result[\"result\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-08T13:16:55.027066Z","iopub.execute_input":"2025-03-08T13:16:55.027410Z","iopub.status.idle":"2025-03-08T13:16:55.037593Z","shell.execute_reply.started":"2025-03-08T13:16:55.027381Z","shell.execute_reply":"2025-03-08T13:16:55.036414Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"#Error correction routine\ndef exec_code_with_fix(llm, query, original_code, attempt=3):\n    NX_FIX_PROMPT = \"\"\"\n    You are an expert at correcting Networkx code. There has been an error\n    in executing code generated.\n    Given an input question, code generated for it, create a revised, syntactically correct code that fixes the error.\n    Input Question:\n    {question}\n    \n    Original Code:\n    {code_err}\n    Only provide the revised python code that I can directly execute via `exec()`. \n    Do not provide any instructions.\n    Revised Code:\n    \"\"\"\n    for i in range(attempt):\n        global_vars = {\"G_adb\": G_adb, \"nx\": nx}\n        local_vars = {}\n        print(f\"\\n2) Executing NetworkX code attempt {i+1}\")\n        print (original_code)\n        try:\n            exec(original_code, global_vars, local_vars)\n            final_code = original_code\n            final_result = local_vars[\"FINAL_RESULT\"]\n            break\n        except:\n            res = llm.invoke(NX_FIX_PROMPT.format(question= query, code_err=original_code))\n            revised_code = re.sub(r\"^```python\\n|```$\", \"\", res.content, flags=re.MULTILINE).strip()\n            original_code = revised_code\n    if \"FINAL_RESULT\" not in local_vars.keys():\n        final_code = revised_code\n        return final_code, \"Unable to execute code\"\n    else:\n        return final_code, final_result","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-08T13:17:01.687277Z","iopub.execute_input":"2025-03-08T13:17:01.687583Z","iopub.status.idle":"2025-03-08T13:17:01.693557Z","shell.execute_reply.started":"2025-03-08T13:17:01.687562Z","shell.execute_reply":"2025-03-08T13:17:01.692459Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"# 5. Define the Text to NetworkX/cuGraph Tool\n# With Error correction \nfrom langchain_core.prompts import PromptTemplate\nimport re\n\n@tool\ndef text_to_nx_algorithm_to_text(query):\n    \"\"\"This tool is available to invoke a NetworkX Algorithm on\n    the ArangoDB Graph. You are responsible for accepting the\n    Natural Language Query, establishing which algorithm needs to\n    be executed, executing the algorithm, and translating the results back\n    to Natural Language, with respect to the original query.\n\n    If the query (e.g traversals, shortest path, etc.) can be solved using the Arango Query Language, then do not use\n    this tool.\n    \"\"\"\n\n    #llm = ChatHuggingFace(llm=hf_coder)\n    if use_model=='gemini':\n        llm  =  ChatGoogleGenerativeAI(\n        model=model_name, #\"gemini-2.0-flash-lite\"\n        temperature=0,\n        max_tokens=None,\n        timeout=None,\n        max_retries=2,\n        # other params...\n        )\n    if use_model=='openai':\n        llm = ChatOpenAI(temperature=0, model_name=model_name)\n\n    ######################\n    print(\"1) Generating NetworkX code\")\n   \n    text_to_nx = llm.invoke(f\"\"\"\n    I have a NetworkX Graph called `G_adb`. It has the following schema: {arango_graph.schema}\n\n    I have the following graph analysis query: {query}.\n\n    Generate the Python Code required to answer the query using the `G_adb` object.\n    Work on `G_adb`.\n\n    Be very precise and efficient on the NetworkX algorithm you select to answer this query. Think step by step.\n\n    Only assume that networkx is installed, and other base python dependencies.\n    Consider the schema carefully when asighning source node, target node and other edege attributes.\n    Do not use subgraphs but find alternative approach. \n    For louvain_communities, convert the graph to undirected if not already.\n    Always set the last variable as `FINAL_RESULT`, which represents the answer to the original query.\n    Only provide python code that I can directly execute via `exec()`. Do not provide any instructions.\n\n    Make sure that `FINAL_RESULT` stores a short & consice answer. Avoid setting this variable to a long sequence.\n    \n    Your code:\n    \"\"\").content\n\n    text_to_nx_cleaned = re.sub(r\"^```python\\n|```$\", \"\", text_to_nx, flags=re.MULTILINE).strip()\n\n    ######################\n    #attemps 3 times to correct the error\n    final_code, FINAL_RESULT = exec_code_with_fix(llm, query, text_to_nx_cleaned, attempt=3)\n    text_to_nx_final = final_code\n    print('-'*10)\n    #FINAL_RESULT = local_vars[\"FINAL_RESULT\"]\n    #print(f\"FINAL_RESULT: {FINAL_RESULT}\")\n    #print('-'*10)\n\n    ######################\n\n    print(\"3) Formulating final answer\")\n\n    nx_to_text = llm.invoke(f\"\"\"\n        I have a NetworkX Graph called `G_adb`. It has the following schema: {arango_graph.schema}\n\n        I have the following graph analysis query: {query}.\n\n        I have executed the following python code to help me answer my query:\n\n        ---\n        {text_to_nx_final}\n        ---\n\n        The `FINAL_RESULT` variable is set to the following: {FINAL_RESULT}.\n\n        Based on my original Query and FINAL_RESULT, generate a short and concise response to\n        answer my query.\n        \n        Your response:\n    \"\"\").content\n\n    return nx_to_text","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-08T13:17:03.563531Z","iopub.execute_input":"2025-03-08T13:17:03.563871Z","iopub.status.idle":"2025-03-08T13:17:03.573516Z","shell.execute_reply.started":"2025-03-08T13:17:03.563843Z","shell.execute_reply":"2025-03-08T13:17:03.572495Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"#We well define the vizulisation tool using plotly\n@tool\ndef text_to_plotly(final):\n    \"\"\"This tool is available to choose appropriately and vizualize plotly figures given data.\n    You are responsible for accepting the data that can be vizualized, establishing which \n    charts are appropriate, executing the vizualization code.\n\n    If the given information is not appropriate for plotting(includes only single result or names) then just return it as is.\n    \"\"\"\n\n    #llm = ChatHuggingFace(llm=hf_coder)\n    #We use gemini-20-flash-lite (the lite version) which while \n    #developing proved better than gemini-2.0.falsh\n    \n    if use_model=='gemini':\n        llm  =  ChatGoogleGenerativeAI(\n        model='gemini-2.0-flash-lite',\n        temperature=0,\n        max_tokens=None,\n        timeout=None,\n        max_retries=2,\n        # other params...\n        )\n    ######################\n    if use_model=='openai':\n        llm = ChatOpenAI(temperature=0, model_name='gpt-4o')\n\n    print(\"1) Generating plotly code\")\n       \n    text_to_plotly = llm.invoke(f\"\"\"\n    \n    I have the following final results: {final}.\n    Generate attractive python Code using plotly to plot the data in this result with \n    appropriate titles, legend and names.\n    Think step by step.\n    Only assume that plotly is installed, and other base python dependencies.\n    Only provide python code that I can directly execute via `exec()`. \n    Do not provide any other instructions or description.\n    Do not use sample data or dummp data in your code but use actual data provided.\n\n    Your code:\n    \"\"\").content\n\n    text_to_plotly_cleaned = re.sub(r\"^```python\\n|```$\", \"\", text_to_plotly, flags=re.MULTILINE).strip()\n    global_vars = {\"plotly\": plotly}\n    local_vars = {}\n\n    try:\n        print ('Executing----plotly code')\n        print(text_to_plotly_cleaned)\n        exec(text_to_plotly_cleaned, global_vars, local_vars)\n        text_to_nx_final = text_to_plotly\n        local_vars['fig'].show()\n        return 'Graph visualized'\n    except Exception as e:\n        print(f\"EXEC ERROR: {e}\")\n        return 'unable to rener graph'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-08T13:36:30.095190Z","iopub.execute_input":"2025-03-08T13:36:30.095639Z","iopub.status.idle":"2025-03-08T13:36:30.106139Z","shell.execute_reply.started":"2025-03-08T13:36:30.095614Z","shell.execute_reply":"2025-03-08T13:36:30.104964Z"}},"outputs":[],"execution_count":57},{"cell_type":"code","source":"import folium\nimport json\nimport numpy as np\n@tool\ndef text_to_map_folium(data):\n    \"\"\"This tool is available specifically for map visualization.\n    You are responsible for accepting the data that can be vizualized, establishing the map center\n    and initital zoom level that encompasses the data and then executing the code to render the\n    map.\n    Do not use sample data but use actual data passed to you.\n    Do not use numpy. Ensure Custom tiles to have an attribution.\n\n    \"\"\"\n\n    #llm = ChatHuggingFace(llm=hf_coder)\n    #We use gemini-20-flash-lite (the lite version) which while \n    #developing proved better than gemini-2.0.falsh\n    \n    if use_model=='gemini':\n        llm  =  ChatGoogleGenerativeAI(\n        model='gemini-2.0-flash-lite',\n        temperature=0,\n        max_tokens=None,\n        timeout=None,\n        max_retries=2,\n        # other params...\n        )\n    ######################\n    if use_model=='openai':\n        llm = ChatOpenAI(temperature=0, model_name='gpt-4o')\n\n    ######################\n    print(\"1) Generating Folium Map Viz\")\n   \n    text_to_map = llm.invoke(f\"\"\"\n    \n    I have the following data: {data}.\n    If not already, convert the data to a list of dictionary having latitude and longitude.\n    Extract all relevant fields.\n    Generate attractive vizualisation code using folium with \n    appropriate titles, legend and names.\n    Think step by step.\n    Only assume that folium and json is installed, and other base python dependencies.\n    Only provide python code that I can directly execute via `exec()`. \n    Do not provide any other instructions or description. Your final output\n    should be a html representation that is rendered.\n\n    Your code:\n    \"\"\").content\n\n    text_to_map_cleaned = re.sub(r\"^```python\\n|```$\", \"\", text_to_map, flags=re.MULTILINE).strip()\n    global_vars = {\"folium\": folium, 'json': json}\n    local_vars = {}\n\n    try:\n        print ('Executing----folium code')\n        print(text_to_map_cleaned)\n        exec(text_to_map_cleaned, global_vars, local_vars)\n        try:\n            local_vars['fig'].show()\n        except:\n            display(local_vars['m'])\n        return local_vars['m']\n    except Exception as e:\n        print(f\"EXEC ERROR: {e}\")\n        return \"vizualisation was unsuccesfull\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-08T14:06:06.534968Z","iopub.execute_input":"2025-03-08T14:06:06.535284Z","iopub.status.idle":"2025-03-08T14:06:06.544573Z","shell.execute_reply.started":"2025-03-08T14:06:06.535263Z","shell.execute_reply":"2025-03-08T14:06:06.543673Z"}},"outputs":[],"execution_count":74},{"cell_type":"markdown","source":"Some time and date handling tools, such as if the query conatains add 5 to current date.\nthen it should get the current dat and use the tool add_time_to_date, passing days=5 to current date","metadata":{}},{"cell_type":"code","source":"from datetime import datetime, timedelta, timezone\nfrom zoneinfo import ZoneInfo\nfrom dateutil import parser\nimport json\nimport typing\n\n@tool\ndef parse_date_time(datetime_str: str) -> str:\n    \"\"\"This tool is available specifically to Parses a date/time string..\n    You are responsible for accepting a datetime string then converting to iso format\n    acceptable for arangodb graphml or node attribute in networkx computations.\n    \"\"\"\n    try:\n        dt = parser.parse(datetime_str)\n        return dt.isoformat()\n    except ValueError:\n        return datetime_str\n        \n@tool\ndef calculate_date_difference(date_str1: str, date_str2: str) -> str:\n    \"\"\"This tool is available specifically to calculate diffrerence between two dates.\n    You are responsible for accepting two date string then calculating the difference between\n    the dates.\n    \"\"\"\n    try:\n        dt1 = parser.parse(date_str1)\n        dt2 = parser.parse(date_str2)\n        delta = dt2 - dt1\n        seconds = delta.total_seconds()\n        days, seconds = divmod(seconds, 86400)\n        hours, seconds = divmod(seconds, 3600)\n        minutes, seconds = divmod(seconds, 60)\n        parts = []\n        if days:\n            parts.append(f\"{int(days)} days\")\n        if hours:\n            parts.append(f\"{int(hours)} hours\")\n        if minutes:\n            parts.append(f\"{int(minutes)} minutes\")\n        if seconds and not parts:\n            parts.append(f\"{int(seconds)} seconds\")\n        if not parts:\n            return \"No Difference.\"\n        return \", \".join(parts)\n    except ValueError:\n        return \"Error: Could not parse date/time strings.\"\n        \n@tool\ndef add_time_to_date(date_str: str, days: int = 0, hours: int = 0, minutes: int = 0) -> str:\n    \"\"\"Your are responsible for adding specific number of days , hours or minutes to a date then\n    return the new datetime.\"\"\"\n    try:\n        dt = parser.parse(date_str)\n        new_dt = dt + timedelta(days=days, hours=hours, minutes=minutes)\n        return new_dt.isoformat()\n    except ValueError:\n        return \"Error: Could not parse date/time string.\"\n\n@tool\ndef subtract_time_to_date(date_str: str, days: int = 0, hours: int = 0, minutes: int = 0) -> str:\n    \"\"\"Your are responsible for subtracting specific number of days , hours or minutes to a date then\n    return the new datetime.\"\"\"\n    try:\n        dt = parser.parse(date_str)\n        new_dt = dt - timedelta(days=days, hours=hours, minutes=minutes)\n        return new_dt.isoformat()\n    except ValueError:\n        return \"Error: Could not parse date/time string.\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-08T13:18:53.368486Z","iopub.execute_input":"2025-03-08T13:18:53.368786Z","iopub.status.idle":"2025-03-08T13:18:53.388663Z","shell.execute_reply.started":"2025-03-08T13:18:53.368765Z","shell.execute_reply":"2025-03-08T13:18:53.387832Z"}},"outputs":[],"execution_count":21},{"cell_type":"markdown","source":"We also define geocode and reverse_geocode, as its more accurate and token efficient for\ndedicated tool to do this rather than llm.","metadata":{}},{"cell_type":"code","source":"from geopy.geocoders import Nominatim\nfrom geopy.exc import GeocoderTimedOut, GeocoderUnavailable\nfrom geopy.geocoders import Nominatim\nfrom geopy.exc import GeocoderTimedOut, GeocoderUnavailable, GeocoderServiceError\n\n@tool\ndef geocode(address: str) -> dict:\n    \"\"\"\n    Converts an address to geographic coordinates. \n\n    Args:\n        address: The address to geocode.\n\n    Returns:\n        A dictionary containing 'latitude' and 'longitude', or None if geocoding fails.\n    \"\"\"\n    \n    geolocator = Nominatim(user_agent=\"my-graphrag-agent\")  # Use a descriptive user agent\n    try:\n        location = geolocator.geocode(address, timeout=5)\n        if location:\n            return {\"latitude\": location.latitude, \"longitude\": location.longitude}\n        else:\n            return 'geocoding error'\n    except (GeocoderTimedOut, GeocoderUnavailable) as e:\n        print(f\"Geocoding error: {e}\")\n        return 'geocoding error' # Consider retrying or using a fallback service\n\n\n@tool\ndef reverse_geocode(latitude: float, longitude: float) -> dict:\n    \"\"\"Converts coordinates to an address, with comprehensive error handling.\n       You take in latitude and longitude float values.\n    Args:\n        latitude: The latitude.\n        longitude: The longitude.\n\n    Returns:\n        A dictionary containing the address (and optionally raw data) if found,\n        or an error dictionary if geocoding fails.\n    \"\"\"\n    geolocator = Nominatim(user_agent=\"my-agent\")\n    try:\n        location = geolocator.reverse((latitude, longitude), timeout=5, language=\"en\")\n        if location:\n            return {\n                \"address\": location.address,\n                \"latitude\": location.latitude, # Include lat/lon in the response\n                \"longitude\": location.longitude,\n                #\"raw\": location.raw,  # Include raw data (optional)\n            }\n        else:\n            return {\"error\": \"Address not found for the given coordinates.\"}\n\n    except GeocoderTimedOut:\n        return {\"error\": \"Geocoding timed out.  Try again later.\"}\n    except GeocoderUnavailable:\n        return {\"error\": \"Geocoding service unavailable.  Check your network connection.\"}\n    except GeocoderServiceError as e:\n        return {\"error\": f\"Geocoding service error: {e}\"} # Catch other service errors\n    except Exception as e:\n        return {\"error\": f\"An unexpected error occurred: {e}\"} # Catch any other exceptions","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-08T13:18:58.666707Z","iopub.execute_input":"2025-03-08T13:18:58.667007Z","iopub.status.idle":"2025-03-08T13:18:58.954705Z","shell.execute_reply.started":"2025-03-08T13:18:58.666984Z","shell.execute_reply":"2025-03-08T13:18:58.953825Z"}},"outputs":[],"execution_count":22},{"cell_type":"markdown","source":"Use API from visualcrossing.com as it allows historical , current and \nfuture precipitation and temperature data goven latitude, longitude and timestamp.\nYou need to have API_KEY from them (FREE) to use this tool","metadata":{}},{"cell_type":"code","source":"#set to false if you prefer not to use this tool, No weather related query\nuse_weather_tool=True ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-08T13:19:03.866797Z","iopub.execute_input":"2025-03-08T13:19:03.867448Z","iopub.status.idle":"2025-03-08T13:19:03.871122Z","shell.execute_reply.started":"2025-03-08T13:19:03.867414Z","shell.execute_reply":"2025-03-08T13:19:03.870348Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"if use_weather_tool:\n    _set_env(\"VISUALCROSSING_API_KEY\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-08T13:19:04.513343Z","iopub.execute_input":"2025-03-08T13:19:04.513659Z","iopub.status.idle":"2025-03-08T13:19:24.843804Z","shell.execute_reply.started":"2025-03-08T13:19:04.513636Z","shell.execute_reply":"2025-03-08T13:19:24.843099Z"}},"outputs":[{"output_type":"stream","name":"stdin","text":"VISUALCROSSING_API_KEY:  ········\n"}],"execution_count":24},{"cell_type":"code","source":"from typing import Dict, Type\nfrom langchain_core.tools import BaseTool\nfrom langchain_core.pydantic_v1 import BaseModel, Field, validator\nimport requests\nimport datetime\nfrom zoneinfo import ZoneInfo\n\nfrom langchain_core.tools import tool\n\n\nclass VisualCrossingInput(BaseModel):\n    latitude: float = Field(..., description=\"Latitude of the location\")\n    longitude: float = Field(..., description=\"Longitude of the location\")\n    timestamp: str = Field(\n        ...,\n        description=\"Timestamp in ISO 8601 format (YYYY-MM-DDTHH:MM) or 'now'\",\n    )\n\n    @validator(\"timestamp\")\n    def validate_timestamp(cls, value):\n        if value.lower() == \"now\":\n            return datetime.datetime.now(tz=ZoneInfo(\"UTC\")).isoformat()\n        try:\n            datetime.datetime.fromisoformat(value.replace(\"Z\", \"+00:00\"))\n            return value\n        except ValueError:\n            raise ValueError(\n                \"Invalid timestamp format. Use ISO 8601 (YYYY-MM-DDTHH:MM) or 'now'.\"\n            )\n\nclass VisualCrossingWeatherTool(BaseTool):\n    name: str = \"get_weather_visualcrossing\"\n    description: str = (  # KEY CHANGE: Added type annotation here\n        \"Retrieves the temperature and precipitation at a specific location and time \"\n        \"using the Visual Crossing Weather API.\"\n    )\n    args_schema: Type[BaseModel] = VisualCrossingInput\n\n    def _run(self, latitude: float, longitude: float, timestamp: str) -> str:\n        \"\"\"Use the tool.\"\"\"\n        api_key = os.getenv('VISUALCROSSING_API_KEY')  # Replace with your API key\n        #latitude, longitude, timestamp = data['latitude'], data['longitude'], data['timestamp']\n        \n        if timestamp.lower() == \"now\":\n            dt_object = datetime.datetime.now(tz=ZoneInfo(\"UTC\"))\n        else:\n            dt_object = (\n                datetime.datetime.fromisoformat(timestamp.replace(\"Z\", \"+00:00\"))\n                .astimezone(ZoneInfo(\"UTC\"))\n            )\n\n        # Construct the API URL\n        date_str = dt_object.strftime(\"%Y-%m-%dT%H:%M:%S\")\n        url = (\n            f\"https://weather.visualcrossing.com/VisualCrossingWebServices/rest/services/timeline/{latitude},{longitude}/{date_str}\"\n            f\"?key={api_key}&unitGroup=metric&include=current\"\n        )\n\n        try:\n            response = requests.get(url)\n            response.raise_for_status()\n            data = response.json()\n\n            # Extract data, handling potential missing values\n            current_conditions = data.get(\"currentConditions\", {})\n            temperature = current_conditions.get(\"temp\")\n            precipitation = current_conditions.get(\"precip\")\n\n            # Build the result string\n            result_parts = []\n            if temperature is not None:\n                result_parts.append(f\"Temperature: {temperature}°C\")\n            else:\n                result_parts.append(\"Temperature: Unavailable\")\n\n            if precipitation is not None:\n                result_parts.append(f\"Precipitation: {precipitation} mm\")\n            else:\n                result_parts.append(\"Precipitation: Unavailable\")\n\n            if result_parts:\n                return (\n                    f\"Weather at ({latitude}, {longitude}) at {timestamp}: \"\n                    + \", \".join(result_parts)\n                )\n            else:\n                return (\n                    f\"Weather data unavailable for ({latitude}, {longitude}) at {timestamp}.\"\n                )\n\n        except requests.exceptions.RequestException as e:\n            return f\"Error during API request: {e}\"\n        except KeyError:\n            return \"Error: Could not retrieve weather data from the API response. Check API key and request.\"\n        except Exception as e:\n            return f\"An unexpected error occurred: {e}\"\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-08T13:19:27.940694Z","iopub.execute_input":"2025-03-08T13:19:27.940994Z","iopub.status.idle":"2025-03-08T13:19:28.097279Z","shell.execute_reply.started":"2025-03-08T13:19:27.940972Z","shell.execute_reply":"2025-03-08T13:19:28.096097Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py:3553: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n\nFor example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\nwith: `from pydantic import BaseModel`\nor the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n\n  exec(code_obj, self.user_global_ns, self.user_ns)\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"def clean_json_string(json_string):\n    \"\"\"\n    Removes or escapes invalid control characters from a JSON string.\n    \"\"\"\n    # Remove control characters (0x00-0x1F, except \\t, \\n, \\r)\n    cleaned_string = re.sub(r'[\\x00-\\x08\\x0b-\\x0c\\x0e-\\x1f]', '', json_string)\n    #The above line would remove all control characters other than \\t (tab), \\n (line feed), and \\r (carriage return)\n    return cleaned_string\n    \ndef remove_control_characters(text):\n    \"\"\"Removes all control characters from a string.\"\"\"\n    # Unicode ranges for control characters:\n    # \\x00-\\x1F: C0 control characters (includes \\t, \\n, \\r)\n    # \\x7F:      Delete character\n    # \\x80-\\x9F: C1 control characters\n    return re.sub(r'[\\x00-\\x1F\\x7F\\x80-\\x9F]', '', text)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-08T13:19:42.603778Z","iopub.execute_input":"2025-03-08T13:19:42.604075Z","iopub.status.idle":"2025-03-08T13:19:42.608273Z","shell.execute_reply.started":"2025-03-08T13:19:42.604053Z","shell.execute_reply":"2025-03-08T13:19:42.607501Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"weather_v = VisualCrossingWeatherTool()\n@tool \ndef get_weather(locdata: str)->dict:\n    \"\"\"\n    Given input text containing flight_code or airport_code, latitude, longitude, timestamp , return weather data\n    \"\"\"\n    result= model.invoke(f\"Locdata: {locdata}\" + \n    \"\"\"Get dict output as id, latitude, longitude, timestamp(if present) of all items in Locdata\n    No explanation or additional information required.\n    example:\n    ```json\n    {'id': 'JFK',\n    'latitude': 0.1,\n    'longitude': 0.1,\n    'timestamp': '2024-07-27T12:00'\n    }\n    Always answer in the following format: {\n    [{\"id\":..., \"latitude\":..., \"longitude\":..., \"timestamp\":...}, \n    {\"id\":..., \"latitude\":..., \"longitude\":..., \"timestamp\":...}]\n    \"\"\")\n    out  = re.sub(r\"^```json\\n|```$\", \"\", result.content, flags=re.MULTILINE).strip()\n    out = json.loads(remove_control_characters(out).replace(\"\\'\", \"\\\"\"))\n    #if not isinstance(out, list):\n    #    out=[out]\n    print(out)\n    weather_data={}\n    for item in out:\n        if \"timestamp\" not in item.keys():\n            item[\"timestamp\"]='now'\n        try:\n            item['timestamp']='now' if item['timestamp'] is None else parse_date_time(item['timestamp'])\n            weather_data[item['id']]= weather_v.invoke(tool_input=item)\n        except:\n            weather_data[item['id']]={}\n    result= model.invoke(f\"\"\"\"Return comma seperated text representing the data in the dictionary {weather_data}\\ \n                           Do mention the id as well, \n                           Example:\n                           id in JFK located in latitude 0.1 and longitude 0.1 had temerature of 23 degree celsius and precipitation of 0.00mm on 02-02-2020,\n                           id in SAN located in latitude 0.3 and longitude 0.4 had temerature of 32 degree celsius and precipitation of 0.5mm on 02-02-2020,\n                           \n                           \"\"\")\n    return result.content","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-08T13:20:11.212163Z","iopub.execute_input":"2025-03-08T13:20:11.212523Z","iopub.status.idle":"2025-03-08T13:20:11.221839Z","shell.execute_reply.started":"2025-03-08T13:20:11.212497Z","shell.execute_reply":"2025-03-08T13:20:11.221026Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"# Test case weather\n#get_weather.invoke('latitude: 34.052235, and the longitude is -118.243683, timestamp is 2020-02-02 ')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-08T13:20:27.611298Z","iopub.execute_input":"2025-03-08T13:20:27.611598Z","iopub.status.idle":"2025-03-08T13:20:27.615043Z","shell.execute_reply.started":"2025-03-08T13:20:27.611577Z","shell.execute_reply":"2025-03-08T13:20:27.614065Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"# Test case add_time_to_date\n\nadd_time_to_date.invoke({'date_str':'02-02-2020', 'days':5})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-08T13:20:21.038271Z","iopub.execute_input":"2025-03-08T13:20:21.038605Z","iopub.status.idle":"2025-03-08T13:20:21.045049Z","shell.execute_reply.started":"2025-03-08T13:20:21.038570Z","shell.execute_reply":"2025-03-08T13:20:21.044075Z"}},"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"'2020-02-07T00:00:00'"},"metadata":{}}],"execution_count":30},{"cell_type":"code","source":"from typing import List\nfrom typing_extensions import TypedDict\nclass ReWOO(TypedDict):\n    task: str\n    plan_string: str\n    steps: List\n    results: dict\n    result: str","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-08T13:20:35.554275Z","iopub.execute_input":"2025-03-08T13:20:35.554616Z","iopub.status.idle":"2025-03-08T13:20:35.558587Z","shell.execute_reply.started":"2025-03-08T13:20:35.554592Z","shell.execute_reply":"2025-03-08T13:20:35.557734Z"}},"outputs":[],"execution_count":32},{"cell_type":"markdown","source":"The main planning ptompt for rewoo","metadata":{}},{"cell_type":"code","source":"prompt = \"\"\"\nTask: {task}\n\nFor the following task, make plans that can solve the problem step by step. For each plan, indicate which external tool together with tool input to retrieve evidence. You can store the evidence into a variable #E that can be called by later tools. (Plan, #E1, Plan, #E2, Plan, ...)\nTo faciliate your planning, here is the graph schema the plans will be executed upoun so plan accordingly.\ngraph schema: {schema}\nTools can be one of the following:\n(1) AQL[input]: Worker that takes in a Natural Language Query then translates it into Structured query language, executes the query and translates the result back into Natural Language. Your input must be natural language, not sql like.\n                Use AQL for geolocation queries or calculation rather than LLM. Latitude and Longitude \n                may be provided as Point coordinates. AQL should also use GEO specific function when presented withgeopgraph\n(2) NX[input]: Worker that invokes a NetworkX Algorithm on the ArangoDB Graph. You are responsible for accepting the Natural Language Query, establishing which algorithm needs to be executed, executing the algorithm, and translating the results back to Natural Language, with respect to the original query. If the query (e.g traversals, shortest path, etc.) can be solved using the AQL worker/tool, then do not use this tool.\n(3) LLM[input]: A pretrained LLM like yourself. Useful when you need to act with general world knowledge and common sense. Prioritize it when you are confident in solving the problem yourself. Input can be any instruction.\n(4) VIZ[input]: Call to evaluate and if feasible  vizualise data that could be plotted using plotly\n(5) MAP[input]: Call to evaluate and if feasible  vizualise as map data that could be plotted using folium.\n                The data should have latitude and longitude.\n(6)GEOCODE[input]: Call to converts an address as string  to geographic coordinates in float. \n(7)REVERSEGEO[input]: Call to Converts coordinates to an string represented address,given latitude and longitude float values.\n(8)PARSEDATE[input]: You are responsible for accepting a datetime string then converting to iso format. This is neeeded when\n                    you are presented date and time in non standard representation.\n(9)DATEDIFF[input]: Calculate diffrerence between two dates.You are responsible for accepting two date string then calculating the difference between the dates.\n(10)ADDDATE[input]: Call to add specific number of days , hours or minutes to a date then return the new datetime.\n(11)SUBDATE[input]: Call to subtract specific number of days , hours or minutes to a date then return the new datetime.\n(12)WEATHER[input]: Call to get the temperature and precipitation. Extracts latitude , longitude and timestamp from string then returns temerature and precipitation in text format\nFor example,\nTask: Determine the most \"central\" airport in Southeast Asia, where \"central\" is defined as the airport that minimizes the average number of flight connections needed to reach other airports within Southeast Asia.\n\nPlan: Define Southeast Asia geographically.  We'll use a list of country codes (ISO 3166-1 alpha-2) for precision.\n#E1 = LLM[Generate a list of ISO 3166-1 alpha-2 country codes for countries in Southeast Asia] (Note: While this could be hardcoded, using an LLM makes the plan more adaptable).  Example: [\"BN\", \"KH\", \"ID\", \"LA\", \"MY\", \"MM\", \"PH\", \"SG\", \"TH\", \"TL\", \"VN\"]\n\nPlan: Find all airports located in the countries defined as Southeast Asia (#E1).\n#E2 = AQL[Find all airports within the countries listed in #E1]\n\nPlan: Retrieve all flights that originate and terminate at airports within Southeast Asia (#E2). This defines the relevant flight network for our analysis.\n#E3 = AQL[Find all flights that both originate and terminate at airports in #E2]\n\nPlan: Load the flight data (#E3) and airport data (#E2) into NetworkX to create a directed graph representing the Southeast Asian flight network.\n#E4 = NX[Create a directed graph from the flight and airport data in #E3 and #E2]\n\nPlan: Calculate the average shortest path length from each airport in Southeast Asia (#E2) to all other reachable airports within Southeast Asia, using the NetworkX graph (#E4). This measures how \"central\" each airport is.\n#E5 = NX[Calculate the average shortest path length from each airport to all other reachable airports within the graph #E4]\n\nPlan: Identify the airport with the minimum average shortest path length. This is the most \"central\" airport according to our definition.\n#E6 = LLM[Analyze the results of #E5 to find the airport with the minimum average shortest path length]\n\nPlan: Present the most central airport (its name and/or IATA code) and its average shortest path length.\n#E7 = LLM[Present the final result - the most central airport and its average shortest path length - based on #E6]\n\nBegin!\nDescribe your plans with rich details. The tool calls the plan invoke are either AQL or Networkx coding agents \nso formulate your plan the releated coding assistant is most likely to accomplish without error.\nMake sure the plan are not repeatious. Make sure networkx operations are efficient i.e obtaing subgraph\nor filtering as required. Input to AQL must be in natural language.\nEach Plan should be followed by only one #E.\n\nReturn a JSON object representing the steps.  Each step should be an object within a \"steps\" array. Each object in array should include keys for \"plan description\" (the plan), \"evidence number\" (the number part of the #E variable, e.g., 1 for #E1), \"tool type\" (the tool name without brackets, e.g., \"AQL\"), and \"input\" (the input to the tool).\n\nThe JSON object should conform to the following schema:\n\n```json\n{{\"steps\": [\n    {{\"plan description\": \"Identify top ten airports with the highest number of connecting flights.\",\n     \"evidence number\": \"1\",\n     \"tool type\": \"NX\",\n     \"input\": \"Identify top ten airports with the highest degree centrality.\"}},\n    {{\"plan description\": \"Extract average connection times for each of these top 10 airports.\",\n     \"evidence number\": \"2\",\n     \"tool type\": \"AQL\",\n     \"input\": \"What are the average durations of connections at [name of each airport in #E1]\"}}\n    ]\n    \"explanation\": \"List of plan and their detailed explanation\"\n}}\nAlways answer in the following json format:\n{{\"steps\": [...], \"explanation\": ... }}\n\"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-08T13:20:42.954468Z","iopub.execute_input":"2025-03-08T13:20:42.954780Z","iopub.status.idle":"2025-03-08T13:20:42.959685Z","shell.execute_reply.started":"2025-03-08T13:20:42.954759Z","shell.execute_reply":"2025-03-08T13:20:42.958727Z"}},"outputs":[],"execution_count":33},{"cell_type":"markdown","source":"We have replaced how regex is used in extracting the step by step plan as there were too many failed parse when using less powerful llm. Having a json structured output is much more robust","metadata":{}},{"cell_type":"code","source":"import json\nimport re\n\ndef clean_and_parse_json(json_string):\n    \"\"\"\n    Cleans a JSON string by removing comments and trailing commas,\n    then attempts to parse it.  Handles multiple concatenated JSON\n    objects and extra data at the end.\n    \"\"\"\n\n    def remove_comments(text):\n        text = re.sub(r'//.*$', '', text, flags=re.MULTILINE)\n        text = re.sub(r'/\\*.*?\\*/', '', text, flags=re.DOTALL)\n        return text\n\n    def remove_trailing_commas(text):\n        return re.sub(r',\\s*([}\\]])', r'\\1', text)\n    #Clean string:\n    json_string = remove_comments(json_string)\n    json_string = remove_trailing_commas(json_string)\n\n    # Try parsing the whole string first\n    try:\n        return json.loads(json_string)\n    except json.JSONDecodeError as e:\n        # If that fails, try parsing multiple objects\n        results = []\n        decoder = json.JSONDecoder()\n        pos = 0\n        while True:\n            try:\n                obj, end = decoder.raw_decode(json_string[pos:])\n                results.append(obj)\n                pos += end\n                match = re.match(r'\\s*,?\\s*', json_string[pos:])\n                if match:\n                    pos += match.end()\n            except json.JSONDecodeError:\n                break  # No more valid JSON\n        return results\n    except Exception as e: #Catch all\n        print (\"Other exception:\", e)\n        return \"unable to parse plan\"\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-08T13:20:45.689925Z","iopub.execute_input":"2025-03-08T13:20:45.690213Z","iopub.status.idle":"2025-03-08T13:20:45.696572Z","shell.execute_reply.started":"2025-03-08T13:20:45.690192Z","shell.execute_reply":"2025-03-08T13:20:45.695568Z"}},"outputs":[],"execution_count":34},{"cell_type":"code","source":"#A refine prompt to refine the plan through critic and feedback. And any additional cases.\nrefine_prompt=\"\"\"You are an expert critic attempting to correct/refine mistake or \nimprove or make more efficient step by step planned task \nthat you made through criticizing and providing feedback .\nHere is the step by step plan: {steps} for the task: {task}.\nYour objective is now to re-evaluate each plan.\nYou have access to the previous explanation: {explanation}.\nYou also know the graph schema as : {graph_schema}. \nAs before,give more preference to AQL usage but use NX when necessary.\nEnsure the tools can output results given the schema.\n\nThe input to AQL must be natural language. \n\nConsidering all these information , critic and refine each plan taking into consideration the previous plan\nand the next plan that will lead to desired outcome. If the individual plan needs\nre-formulation then do so.\n\nReturn a JSON object representing the modified steps.  \nEach step should be an object within a \"steps\" array. \nEach object in array should include keys for \"plan description\" (the plan), \"evidence number\" (the number part of the #E variable, e.g., 1 for #E1), \"tool type\" (the tool name without brackets, e.g., \"AQL\"), and \"input\" (the input to the tool).\n\nReturn a JSON object representing the steps.  Each step should be an object within a \"steps\" array. Each object in array should include keys for \"plan description\" (the plan), \"evidence number\" (the number part of the #E variable, e.g., 1 for #E1), \"tool type\" (the tool name without brackets, e.g., \"AQL\"), and \"input\" (the input to the tool).\n\nThe JSON object should conform to the following schema:\n\n```json\n{{\"steps\": [\n    {{\"plan description\": \"Identify top ten airports with the highest number of connecting flights.\",\n     \"evidence number\": \"1\",\n     \"tool type\": \"NX\",\n     \"input\": \"Identify top ten airports with the highest degree centrality.\"}},\n    {{\"plan description\": \"Extract average connection times for each of these top 10 airports.\",\n     \"evidence number\": \"2\",\n     \"tool type\": \"AQL\",\n     \"input\": \"What are the average durations of connections at [name of each airport in #E1]\"}}\n    ]\n    \"explanation\": \"List of plan and their detailed explanation\"\n}}\nAlways answer in the following json format:\n{{\"steps\": [...], \"explanation\": ... }}\n\"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-08T13:20:47.766421Z","iopub.execute_input":"2025-03-08T13:20:47.766805Z","iopub.status.idle":"2025-03-08T13:20:47.770822Z","shell.execute_reply.started":"2025-03-08T13:20:47.766776Z","shell.execute_reply":"2025-03-08T13:20:47.769868Z"}},"outputs":[],"execution_count":35},{"cell_type":"code","source":"#get the plan and replan functions\nimport re\nfrom langchain.output_parsers import ResponseSchema, StructuredOutputParser\nfrom langchain_core.prompts import ChatPromptTemplate\nimport json\n\nprompt_template = ChatPromptTemplate.from_messages([(\"user\", prompt)])\nplanner = prompt_template | model\n\nre_prompt_template = ChatPromptTemplate.from_messages([(\"user\", refine_prompt)])\nre_planner = re_prompt_template | model\n\n\ndef get_plan(state: ReWOO):\n    task = state[\"task\"]\n    result = planner.invoke({\"task\": task, 'schema': arango_graph.schema})\n    out  = re.sub(r\"^```json\\n|```$\", \"\", result.content, flags=re.MULTILINE).strip()\n    out = json.loads(remove_control_characters(out))\n    #re_result= re_planner.invoke({'task': task, 'steps': out['steps'], 'graph_schema': arango_graph.schema,  \n    #                         'explanation': out['explanation']})\n    #out  = re.sub(r\"^```json\\n|```$\", \"\", re_result.content, flags=re.MULTILINE).strip()\n    #out = json.loads(remove_control_characters(out))\n    return {\"steps\": [tuple([str(vi) for vi in v.values()]) for v in out['steps']], \"plan_string\": out['explanation']}\n\ndef get_replan(state: ReWOO):\n    task = state[\"task\"]\n    steps = state['steps']\n    re_result= re_planner.invoke({'task': task, 'steps': steps, 'graph_schema': arango_graph.schema,  \n                             'explanation': state['plan_string']})\n    out  = re.sub(r\"^```json\\n|```$\", \"\", re_result.content, flags=re.MULTILINE).strip()\n    out = json.loads(remove_control_characters(out))\n    state['steps'] = [tuple([str(vi) for vi in v.values()]) for v in out['steps']]\n    state['plan_string'] = out['explanation']\n    return {\"steps\": state['steps'], \"plan_string\": state['plan_string']}\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-08T13:20:49.756939Z","iopub.execute_input":"2025-03-08T13:20:49.757334Z","iopub.status.idle":"2025-03-08T13:20:49.796510Z","shell.execute_reply.started":"2025-03-08T13:20:49.757302Z","shell.execute_reply":"2025-03-08T13:20:49.795664Z"}},"outputs":[],"execution_count":36},{"cell_type":"code","source":"def _get_current_task(state: ReWOO):\n    if \"results\" not in state or state[\"results\"] is None:\n        return 1\n    if len(state[\"results\"]) == len(state[\"steps\"]):\n        return None\n    else:\n        return len(state[\"results\"]) + 1\n\n#How the tools and tool input are invoked step by step\ndef tool_execution(state: ReWOO):\n    \"\"\"Worker node that executes the tools of a given plan.\"\"\"\n    _step = _get_current_task(state)\n    _, step_name, tool, tool_input = state[\"steps\"][_step - 1]\n    _results = (state[\"results\"] or {}) if \"results\" in state else {}\n    for k, v in _results.items():\n        tool_input = tool_input.replace(k, v)\n    if tool == \"LLM\":\n         result = model.invoke(tool_input)\n    elif tool == \"AQL\":\n        result = text_to_aql_to_text.invoke(tool_input)\n    elif tool == \"NX\":\n        result = text_to_nx_algorithm_to_text.invoke(tool_input)\n    elif tool=='VIZ':\n        result = text_to_plotly.invoke(tool_input)\n    elif tool=='MAP':\n        result = text_to_map_folium.invoke(tool_input)\n    elif tool=='GEOCODE':\n        result = geocode.invoke(tool_input)\n    elif tool=='REVERSEGEO':\n        result = reverse_geocode.invoke(tool_input)\n    elif tool=='PARSEDATE':\n        result = parse_date_time.invoke(tool_input)\n    elif tool=='DATEDIFF':\n        result = calculate_date_difference.invoke(tool_input)\n    elif tool=='ADDDATE':\n        result = add_time_to_date.invoke(tool_input)\n    elif tool=='SUBDATE':\n        result = subtract_time_to_date.invoke(tool_input)\n    elif tool=='WEATHER':\n        if use_weather_tool:\n            result = get_weather.invoke(tool_input)\n        else:\n            return \"no weather tool so no data\"\n    else:\n        raise ValueError\n    _results[step_name] = str(result)\n    return {\"results\": _results}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-08T13:20:51.772441Z","iopub.execute_input":"2025-03-08T13:20:51.772771Z","iopub.status.idle":"2025-03-08T13:20:51.779990Z","shell.execute_reply.started":"2025-03-08T13:20:51.772744Z","shell.execute_reply":"2025-03-08T13:20:51.779156Z"}},"outputs":[],"execution_count":37},{"cell_type":"code","source":"solve_prompt = \"\"\"Solve the following task or problem. To solve the problem, we have made step-by-step Plan and \\\nretrieved corresponding Evidence to each Plan. Use them with caution since long evidence might \\\ncontain irrelevant information.\n\n{plan}\n\nNow solve the question or task according to provided Evidence above. Respond with the answer\ndirectly with no extra words.\n\nTask: {task}\nResponse:\"\"\"\n\n\ndef solve(state: ReWOO):\n    plan = \"\"\n    for _plan, step_name, tool, tool_input in state[\"steps\"]:\n        _results = (state[\"results\"] or {}) if \"results\" in state else {}\n        for k, v in _results.items():\n            tool_input = tool_input.replace(k, v)\n            step_name = step_name.replace(k, v)\n        plan += f\"Plan: {_plan}\\n{step_name} = {tool}[{tool_input}]\"\n    prompt = solve_prompt.format(plan=plan, task=state[\"task\"])\n    result = model.invoke(prompt)\n    return {\"result\": result.content}\n\ndef _route(state):\n    _step = _get_current_task(state)\n    if _step is None:\n        # We have executed all tasks\n        return \"solve\"\n    else:\n        # We are still executing tasks, loop back to the \"tool\" node\n        return \"tool\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-08T13:20:53.850242Z","iopub.execute_input":"2025-03-08T13:20:53.850571Z","iopub.status.idle":"2025-03-08T13:20:53.855872Z","shell.execute_reply.started":"2025-03-08T13:20:53.850544Z","shell.execute_reply":"2025-03-08T13:20:53.855305Z"}},"outputs":[],"execution_count":38},{"cell_type":"markdown","source":"#(optional) review prompt that evaluates how the task was executed\n#very usefull for debuging, but currently not added to the graph ","metadata":{"execution":{"iopub.status.busy":"2025-03-08T13:20:56.101090Z","iopub.execute_input":"2025-03-08T13:20:56.101432Z","iopub.status.idle":"2025-03-08T13:20:56.104694Z","shell.execute_reply.started":"2025-03-08T13:20:56.101404Z","shell.execute_reply":"2025-03-08T13:20:56.103908Z"}}},{"cell_type":"code","source":"review_prompt =\"\"\"\"Were you able to solve the task: {task} as now you \nknow the results from all the steps in: {steps} you took. \nIf not, determine and show \nexactly where you failed and what you could have done differently to solve the task.\nIf you think the task was unsolvable provided the tools you had then  state this\nand why. Summarize your analysis with a clear and concise response.\n\nYour response:\n\"\"\"\ndef review_answer(state: ReWOO):\n    steps = state['steps']\n    results = state['results']\n    \n    prompt = review_prompt.format(task = state['task'], \n                           steps = steps)\n    result = model.invoke(prompt)\n    return {\"result\": result.content}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-08T13:21:06.995090Z","iopub.execute_input":"2025-03-08T13:21:06.995442Z","iopub.status.idle":"2025-03-08T13:21:06.999820Z","shell.execute_reply.started":"2025-03-08T13:21:06.995414Z","shell.execute_reply":"2025-03-08T13:21:06.998859Z"}},"outputs":[],"execution_count":41},{"cell_type":"code","source":"from langgraph.graph import END, StateGraph, START\n\ngraph = StateGraph(ReWOO)\ngraph.add_node(\"plan\", get_plan)\ngraph.add_node(\"replan\", get_replan)\ngraph.add_node(\"tool\", tool_execution)\ngraph.add_node(\"solve\", solve)\n#graph.add_node(\"review\", review_answer)\n\ngraph.add_edge(\"plan\", \"replan\")\ngraph.add_edge(\"replan\", \"tool\")\n#add edge solve to review and review to end for using review ,\n#graph_ad_edge('solve', 'review')\n#graph.add_edge(\"review\", END)\ngraph.add_edge(\"solve\", END)\ngraph.add_conditional_edges(\"tool\", _route)\ngraph.add_edge(START, \"plan\")\n\napp = graph.compile()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-08T13:21:07.481057Z","iopub.execute_input":"2025-03-08T13:21:07.481356Z","iopub.status.idle":"2025-03-08T13:21:07.541942Z","shell.execute_reply.started":"2025-03-08T13:21:07.481335Z","shell.execute_reply":"2025-03-08T13:21:07.541073Z"}},"outputs":[],"execution_count":42},{"cell_type":"code","source":"app","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-08T13:21:11.825926Z","iopub.execute_input":"2025-03-08T13:21:11.826239Z","iopub.status.idle":"2025-03-08T13:21:11.920500Z","shell.execute_reply.started":"2025-03-08T13:21:11.826199Z","shell.execute_reply":"2025-03-08T13:21:11.919657Z"}},"outputs":[{"execution_count":43,"output_type":"execute_result","data":{"text/plain":"<langgraph.graph.state.CompiledStateGraph object at 0x7b2f2e7467d0>","image/png":"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\n"},"metadata":{}}],"execution_count":43},{"cell_type":"code","source":"q0 = \"\"\"What was the temerature  on 02-02-2020 at all airports in HI. Show me map view with\nappropriate color\"\"\"\nq1=\"\"\"Identify 'ghost airports' – \nairports that are geographically central within the network (high betweenness centrality) \nbut have surprisingly low direct flight connections (low degree centrality). \nShow map of these 'ghost airports'\"\n\"\"\"\nq2=\"\"\"\nFor all destination airport of LAX, create a 'travel influence' metric that combines the distance to\nthem and unique airlines serving them. Show map view with markers denoting the travel influence.\n\"\"\"\nq3=\"\"\"Due to a system-wide outage at United Airlines ('UA'), \nall their flights are canceled. Which airports that they normally fly to \nwould then have no connections at all to the rest of the air transportation network?\"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-08T14:07:03.929958Z","iopub.execute_input":"2025-03-08T14:07:03.930293Z","iopub.status.idle":"2025-03-08T14:07:03.934071Z","shell.execute_reply.started":"2025-03-08T14:07:03.930264Z","shell.execute_reply":"2025-03-08T14:07:03.933404Z"}},"outputs":[],"execution_count":76},{"cell_type":"code","source":"from rich import print","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-08T13:33:07.514735Z","iopub.execute_input":"2025-03-08T13:33:07.515105Z","iopub.status.idle":"2025-03-08T13:33:07.519176Z","shell.execute_reply.started":"2025-03-08T13:33:07.515074Z","shell.execute_reply":"2025-03-08T13:33:07.518115Z"}},"outputs":[],"execution_count":54},{"cell_type":"markdown","source":"Remeber you the api from https://www.visualcrossing.com to use their weather related services(There is FREE plan)","metadata":{}},{"cell_type":"code","source":"qq=q0\nprint (qq)\nfor s in app.stream({\"task\": qq}):\n    if 'replan' in s.keys():\n        for p in s['replan']['steps']:\n            print (p)\n        print(s['replan']['plan_string'])\n    if 'solve' in s.keys():\n        print ('solution::', s['solve']['result'])\n    \n    print(\"---\")\n    \nprint ('######################################################################################')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print('done..')","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}